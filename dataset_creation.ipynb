{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13534fb-a2e5-4134-96f2-39cde1fe9577",
   "metadata": {},
   "source": [
    "# Notebook: Generation of image and label datasets\n",
    "\n",
    "Generate datasets of roof segment labels for aerial imagery derived from CityGML semantic 3D city models for semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf019e2-aa44-4ce8-8a30-719ccaaee7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "import shapely\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from owslib.wms import WebMapService\n",
    "from owslib.util import Authentication\n",
    "\n",
    "# Importing WMS username and password\n",
    "from wms_config import username as wms_username, password as wms_password\n",
    "\n",
    "from dataset_creation_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f27f26-678a-441d-947c-51f200c3502d",
   "metadata": {},
   "source": [
    "# Data import and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef4af4-c3b1-4604-b722-832075aecd36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Special case: How to create samples at wbg_m (aka _small-manu_) centroids with 3DCityDB segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1b397-6659-40da-8a6c-fe5b2e89ad71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "For the configuration _small-auto_, it is necessary to create samples around the _small-manu_ building centroids using the _small-auto_ segment geometries.\n",
    "\n",
    "1. Load wbg_m / small-manu segments from \"Import segments\" section.\n",
    "2. Convert to EPSG:25832\n",
    "3. Derive buildings, centroids, and buffers.\n",
    "4. Filter buildings: Run the cell at section \"Perform data split > Prepare hand-labeled dataset: Filter out buildings without image/label pair\"\n",
    "5. Use \"Import segments\" section again, this time to load 3DCityDB segments of Wartenberg, small-auto.\n",
    "6. DON'T recompute the buildings, keep the pvbackend building dataframe.\n",
    "7. Run sections to create dataset using the Web Map Service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b64529-dc70-45c3-9586-bfda8203d35a",
   "metadata": {},
   "source": [
    "## Import segments and set up GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d68bd9-88c7-4947-a967-d59d925c9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select configuration\n",
    "scenario = \"small-manu\"\n",
    "\n",
    "# set input data parameters:\n",
    "# tables with roof segment geometries\n",
    "segments_dirpath = \"segments\"\n",
    "segments_filenames = {\n",
    "    \"small-manu\":                         \"segments_small-manu.csv\",\n",
    "    \"small-auto\":                         \"segments_small-auto.csv\",\n",
    "    \"large-auto\":                         \"segments_large-auto.csv\",  # Bavaria dataset including column indicating roof generation method\n",
    "    \"large-auto_legacy\":                  \"segments_large-auto_legacy.csv\",\n",
    "    \"large-auto_legacy_Erding_Freising\":  \"segments_large-auto_legacy_Erding_Freising.csv\",\n",
    "    \"large-auto_legacy_Munich\":           \"segments_large-auto_legacy_Munich.csv\",\n",
    "    \"large-auto_legacy_Rural\":            \"segments_large-auto_legacy_Rural.csv\"\n",
    "}\n",
    "\n",
    "# CRS of roof segment data\n",
    "# epsg:25832 for LDBV 3DCityDB data and aerial imagery\n",
    "# epsg:4326 for Google Satellite data and imagery\n",
    "segments_crss = {\n",
    "    \"small-manu\":                         \"epsg:4326\",\n",
    "    \"small-auto\":                         \"epsg:25832\",\n",
    "    \"large-auto\":                         \"epsg:25832\",\n",
    "    \"large-auto_legacy\":                  \"epsg:25832\",\n",
    "    \"large-auto_legacy_Erding_Freising\":  \"epsg:25832\",\n",
    "    \"large-auto_legacy_Munich\":           \"epsg:25832\",\n",
    "    \"large-auto_legacy_Rural\":            \"epsg:25832\",\n",
    "}\n",
    "\n",
    "# set segments filepath and CRS\n",
    "segments_filepath = os.path.join(segments_dirpath, segments_filenames[scenario])\n",
    "segments_crs = segments_crss[scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f459cc2-4d54-4c8d-9e4e-40a7a5de3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "segments = gpd.read_file(segments_filepath, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "segments.crs = segments_crs\n",
    "\n",
    "# some data corrections, apply numeric data types\n",
    "segments.loc[segments[\"azimuth\"] == \"NaN\", \"azimuth\"] = \"\"\n",
    "segments.loc[segments[\"slope\"] == \"NaN\", \"slope\"] = \"\"\n",
    "segments[\"azimuth\"] = pd.to_numeric(segments[\"azimuth\"])\n",
    "segments[\"slope\"] = pd.to_numeric(segments[\"slope\"])\n",
    "segments[\"b_id\"] = segments[\"b_id\"].astype(int)\n",
    "segments[\"sg_id\"] = segments[\"sg_id\"].astype(int)\n",
    "\n",
    "# derive orientation classes from azimuth angle: parameter setup\n",
    "# directions / angles used here: north = -180째, east = -90째, south = 0째, west = 90째\n",
    "bin_width = 22.5\n",
    "angle_bins = [-180 - bin_width/2 + k * bin_width for k in range(0,18)]\n",
    "labels = [\"n\", \"nne\", \"ne\", \"ene\", \"e\", \"ese\", \"se\", \"sse\", \"s\", \"ssw\", \"sw\", \"wsw\", \"w\", \"wnw\", \"nw\", \"nnw\", \"n\"]\n",
    "\n",
    "# sort segment azimuth angles into 16 bins\n",
    "segments[\"orientation\"] = pd.Series(pd.cut(segments[\"azimuth\"], angle_bins, labels = labels, ordered=False))\n",
    "\n",
    "# add category \"flat\" to orientation categorical\n",
    "segments[\"orientation\"] = segments[\"orientation\"].cat.add_categories(\"flat\")\n",
    "\n",
    "# turn NaN orientation resulting from NaN azimuth into \"flat\"\n",
    "segments.loc[pd.isna(segments[\"orientation\"]), \"orientation\"] = \"flat\"\n",
    "\n",
    "# dict to translate into numerical orientation classes\n",
    "# note: background has class value 0, this value is assigned automatically to image areas\n",
    "# without segment by rasterio.features.rasterize() used in save_png_labels().\n",
    "orientation_dict = {\n",
    "    \"n\": 1,\n",
    "    \"nne\": 2,\n",
    "    \"ne\": 3,\n",
    "    \"ene\": 4,\n",
    "    \"e\": 5,\n",
    "    \"ese\": 6,\n",
    "    \"se\": 7,\n",
    "    \"sse\": 8,\n",
    "    \"s\": 9,\n",
    "    \"ssw\": 10,\n",
    "    \"sw\": 11,\n",
    "    \"wsw\": 12,\n",
    "    \"w\": 13,\n",
    "    \"wnw\": 14,\n",
    "    \"nw\": 15,\n",
    "    \"nnw\": 16,\n",
    "    \"flat\": 17\n",
    "}\n",
    "\n",
    "# Alternative class values with background class getting value 17 instead of 0.\n",
    "# If you use them to generate a new dataset, remember to change fill value for background class to 17 (in function save_png_labels).\n",
    "\"\"\"\n",
    "orientation_dict = {\n",
    "    \"n\": 0,\n",
    "    \"nne\": 1,\n",
    "    \"ne\": 2,\n",
    "    \"ene\": 3,\n",
    "    \"e\": 4,\n",
    "    \"ese\": 5,\n",
    "    \"se\": 6,\n",
    "    \"sse\": 7,\n",
    "    \"s\": 8,\n",
    "    \"ssw\": 9,\n",
    "    \"sw\": 10,\n",
    "    \"wsw\": 11,\n",
    "    \"w\": 12,\n",
    "    \"wnw\": 13,\n",
    "    \"nw\": 14,\n",
    "    \"nnw\": 15,\n",
    "    \"flat\": 16\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# assign numerical orientation classes\n",
    "segments['orientation_num'] = segments['orientation'].map(orientation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6c380-164c-4a07-afef-81de8d58b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only apply for pvbackend-segments (orignal hand-labelled segments) for execution of data split\n",
    "# to make sure the buffers of the buildings correspond to the actual image size:\n",
    "# projection to epsg:25832\n",
    "if segments.crs == \"epsg:4326\": segments = segments.to_crs(\"epsg:25832\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5033667-6336-4459-8514-2a0a1293e6d1",
   "metadata": {},
   "source": [
    "## Derive buildings from segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d815e-916f-4ac9-8438-a781493df2ce",
   "metadata": {},
   "source": [
    "Two options (A) and (B) depending on whether the column \"method\", indicative of the roof generation method / algorithm, is available or not.\n",
    "\n",
    "### A) If column \"method\" is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ce304-639d-443a-a69b-fee68e59944c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dissolve / aggregate segment geometries by building id\n",
    "buildings = segments[[\"b_id\", \"geometry\"]].dissolve(by = \"b_id\", as_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e48845-18e3-46ce-b9b2-b54296424cbf",
   "metadata": {},
   "source": [
    "### B) If column \"method\" is available:\n",
    "\n",
    "Column method: roof geometry generation method, generic attribute from 3D city data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c05b3b-9f53-4b56-a072-dd07d444332a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dissolve / aggregate segment geometries by building id\n",
    "buildings = segments[[\"b_id\", \"method\", \"geometry\"]].dissolve(by = \"b_id\", as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41218bef-bbb8-43c3-b4db-0bc3afd9974c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments[\"method\"].value_counts(), segments[\"method\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05886494-c4c2-470d-b175-606f1c741cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buildings[\"method\"].value_counts(), buildings[\"method\"].count(), buildings.loc[buildings[\"method\"].isin([\"3210\", \"3220\", \"3100\"]), \"method\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccc797-aa22-4652-8ab5-9091643cbe6c",
   "metadata": {},
   "source": [
    "## Compute centroids and sample-sized buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028172d-62fe-4f07-a492-e06d44661c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params:\n",
    "# - img_size_px: square image side length in pixels\n",
    "# - img_res_m_per_pix: resolution of imagery in meters per pixel\n",
    "img_size_px = 256\n",
    "img_res_m_per_px = 0.2\n",
    "img_size_m = img_size_px * img_res_m_per_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d875a23-5307-43c8-85ed-e7baed7dd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids\n",
    "buildings[\"centroid\"] = buildings.centroid\n",
    "\n",
    "# create square buffers around buildings to crop / retrieve aerial image\n",
    "buildings[\"buffer\"] = buildings[\"centroid\"].buffer(img_size_m/2, cap_style=3)\n",
    "\n",
    "# number of buildings that are not contained within the image-sized buffer\n",
    "sum(buildings[\"buffer\"].contains(buildings[\"geometry\"]) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b281c9-d870-4b9c-aeb7-a8cb30921f26",
   "metadata": {},
   "source": [
    "## Remove samples with false labels (default flat roofs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd8d0b-1654-4b46-9e22-6d20e218c22f",
   "metadata": {},
   "source": [
    "Only if column \"method\" is available. Two options (A) or (B). Variant (B) was used to generate the dataset bv_nfl aka _large-auto_. Variant (A), which is more exact, was implemented afterwards but the improvement was deemed too minor (gain of 260 samples) to re-do the data split and re-train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9a009-fa70-4eb9-ad9c-8d9815ab6379",
   "metadata": {},
   "source": [
    "### A) Exact method\n",
    "\n",
    "First uses sindex.query to check for intersecting envelopes and in a second step uses sjoin to check for exact intersections. Takes longer, but saves some buildings from unnecessarily being sorted out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1715227-c1f2-4d84-9d29-888470107616",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_containing_false_labels = np.array([], dtype = np.int64)\n",
    "\n",
    "# list of roof generation methods that indicate assignemnt of a default flat roof\n",
    "undesirable_geom_methods = [\"3210\", \"3220\", \"3100\"]\n",
    "\n",
    "for index, building in buildings.iterrows():\n",
    "    \n",
    "    # identify all buildings that intersect the current building's buffer\n",
    "    intersecting_buildings = buildings.iloc[buildings.sindex.query(building[\"buffer\"])]\n",
    "    \n",
    "    # if among these there are any with undesired roof geometry generation method\n",
    "    if len(intersecting_buildings[intersecting_buildings[\"method\"].isin(undesirable_geom_methods)]) > 0:\n",
    "        \n",
    "        buffer_gdf = gpd.GeoDataFrame({\"geometry\": building[\"buffer\"]}, index = [0])\n",
    "        buffer_gdf.crs = segments_crs\n",
    "        \n",
    "        intersecting_buildings_2 = intersecting_buildings.sjoin(buffer_gdf, how = \"inner\", predicate = \"intersects\")\n",
    "        \n",
    "        if len(intersecting_buildings_2[intersecting_buildings_2[\"method\"].isin(undesirable_geom_methods)]) > 0:\n",
    "        \n",
    "            samples_containing_false_labels = np.append(\n",
    "                samples_containing_false_labels,\n",
    "                building[\"b_id\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2f767-209d-4828-b642-0053361e7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_containing_false_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a89514-1d12-4cd9-926c-305999e85d58",
   "metadata": {},
   "source": [
    "### B) Not quite as exact method\n",
    "\n",
    "Only uses sindex.query to check for intersecting envelopes. Faster, but leads to sorting out of a few samples that could be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845281a-a6ec-47e2-91ce-a7231e422e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_containing_false_labels = np.array([], dtype = np.int64)\n",
    "undesirable_geom_methods = [\"3210\", \"3220\", \"3100\"]\n",
    "\n",
    "for index, building in buildings.iterrows():\n",
    "    \n",
    "    # identify all buildings that intersect the current building's buffer\n",
    "    intersecting_buildings = buildings.iloc[buildings.sindex.query(building[\"buffer\"])]\n",
    "    \n",
    "    # if among these there are any with undesired roof geometry generation method\n",
    "    if len(intersecting_buildings[intersecting_buildings[\"method\"].isin(undesirable_geom_methods)]) > 0:\n",
    "        \n",
    "        samples_containing_false_labels = np.append(\n",
    "            samples_containing_false_labels,\n",
    "            building[\"b_id\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f5164-91aa-4d8d-8913-433444bf4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_containing_false_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb986ce1-3c7b-4729-bc03-f92b23ef1ad5",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "If only using the sindex.query as intersection method, which only intersects envelopes / bounding boxes of the features, the resulting number of buildings within whose sample extent there are false labels is 28560.\n",
    "\n",
    "If additionally using sjoin as intersection method after sindex.query found intersecting envelopes of false labels to sort out any buildings with false labels whose envelope intersects the buffer but whose exact geometry does not, the resulting number of buildings within whose sample extent there are false labels is 28300.\n",
    "\n",
    "The difference is, therefore, quite negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842b026-8ad1-4bac-a3a9-4356faa3f655",
   "metadata": {},
   "source": [
    "Next cell: Filters out undesired samples, must be executed after identifying them using (A) or (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28112cc-bc9a-4638-9e4a-dd70200e9a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buildings_complete = buildings\n",
    "buildings = buildings[~buildings[\"b_id\"].isin(samples_containing_false_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a94a39-06e5-4959-a0e8-7e79b9514ea8",
   "metadata": {},
   "source": [
    "# Plot study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db4cfc-ba15-4704-9d82-c6bcd6b6646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3f7cd-01b6-4f70-8295-599665428adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_dir = \"Plots\"\n",
    "save_fig = False\n",
    "\n",
    "plotsize_px = 3000\n",
    "figsize_inches = 10\n",
    "dpi = plotsize_px / figsize_inches\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    figsize = (figsize_inches, figsize_inches),\n",
    "    dpi = dpi, \n",
    "    constrained_layout = True\n",
    ")\n",
    "\n",
    "buildings.plot(ax = ax, color = \"black\")\n",
    "if save_fig:\n",
    "    fig.savefig(os.path.join(plot_dir, \"\".join([\"buildings_\", scenario, \"_\", str(plotsize_px), \"_\", str(figsize_inches), \".png\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825f353-1a1c-4a6f-b47c-cc0bfd466920",
   "metadata": {},
   "source": [
    "# Create dataset of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df240515-f541-41c9-a6ab-ff718efed322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure Windows' controlled folder access allows Python to write in folder if protected\n",
    "dataset_dirpath = r\"datasets\"\n",
    "dataset_dirname = \"dataset_wbg_a\"\n",
    "images_dirpath = os.path.join(dataset_dirpath, dataset_dirname, \"images\")\n",
    "labels_dirpath = os.path.join(dataset_dirpath, dataset_dirname, \"labels\")\n",
    "if not os.path.exists(images_dirpath): os.makedirs(images_dirpath)\n",
    "if not os.path.exists(labels_dirpath): os.makedirs(labels_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9be8b-c7ea-45a9-a9ed-ac10cdcb6453",
   "metadata": {},
   "source": [
    "## 3D city data based labels: Using DOP WMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb99ab6-6904-4a3c-95e0-59667c343304",
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate = Authentication()\n",
    "\n",
    "# connect to Web Map Service\n",
    "wms = WebMapService('https://geoservices.bayern.de/wms/v2/ogc_dop20.cgi?',\n",
    "                    version = '1.1.1',\n",
    "                    xml = None, \n",
    "                    username = wms_username,\n",
    "                    password = wms_password, \n",
    "                    parse_remote_metadata = False, \n",
    "                    timeout = 180,\n",
    "                    headers = None, \n",
    "                    auth = authenticate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a768251-f0db-4273-9426-afad8b4c3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_total = time.time()\n",
    "\n",
    "start = 0\n",
    "stop = len(buildings)\n",
    "\n",
    "for index, row in buildings[start:stop].iterrows():\n",
    "    \n",
    "    #begin = time.time()\n",
    "    \n",
    "    # obtain crop of aerial image at building location from WMS\n",
    "    tile = wms.getmap(layers = ['by_dop20c'],\n",
    "                      styles = ['default'],\n",
    "                      srs = 'EPSG:25832',\n",
    "                      bbox = row[\"buffer\"].bounds,\n",
    "                      size = (img_size_px, img_size_px),\n",
    "                      format = 'image/tiff',\n",
    "                      transparent = True)\n",
    "    \n",
    "    image_filename = str(row[\"b_id\"]) + \".tif\"\n",
    "    image_filepath = os.path.join(images_dirpath, image_filename)\n",
    "    \n",
    "    out = open(image_filepath, \"wb\")\n",
    "    out.write(tile.read())\n",
    "    out.close()\n",
    "    \n",
    "    #print(\"Fetched and saved WMS image crop in \" + str(time.time() - begin) + \" seconds.\")\n",
    "    #begin = time.time()\n",
    "    \n",
    "    # get segments that intersect the building's buffer\n",
    "    label_segments = get_label_segments_sindex(segments = segments,\n",
    "                                               crop_geometry = row[\"buffer\"])\n",
    "    \n",
    "    #print(\"Fetched required segments in \" + str(time.time() - begin) + \" seconds.\")\n",
    "    #begin = time.time()\n",
    "    \n",
    "    # Attempt to obtain transform without having to read the corresponding image file - not functional\n",
    "    #bbox = row[\"buffer\"].bounds\n",
    "    #transform = rasterio.transform.from_bounds(bbox[1],bbox[0],bbox[3],bbox[2], img_size_px, img_size_px)\n",
    "    \n",
    "    # rasterize these segments and save them as label pngs\n",
    "    with rasterio.open(image_filepath) as image:\n",
    "        save_png_labels(segments_geometry = label_segments[\"geometry\"],\n",
    "                        segments_orientation = label_segments[\"orientation_num\"],\n",
    "                        shape = (img_size_px, img_size_px),\n",
    "                        transform = image.transform,\n",
    "                        dirpath = labels_dirpath,\n",
    "                        filename = str(row[\"b_id\"]))\n",
    "    \n",
    "    #print(\"Saved required segments in \" + str(time.time() - begin) + \" seconds.\")\n",
    "    \n",
    "    print(f\"Sample {str(index+1)} done.\", end = \"\\r\")\n",
    "    \n",
    "end_total = time.time()\n",
    "seconds = end_total - begin_total\n",
    "\n",
    "print(\"Created {} training samples in {} seconds.\".format(str(stop-start), str(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2c842-05f7-40e1-80bc-47b6369ef1f3",
   "metadata": {},
   "source": [
    "## 3D city data based labels: Using local DOP mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf00091-355d-4da1-bfe5-c47be947cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "save_img_as_png = False\n",
    "save_img_as_tif = True\n",
    "in_filepath = r\"mosaic.tif\"\n",
    "\n",
    "# convert buffer geometries to json (required by rasterio.mask)\n",
    "buildings[\"buffer_json\"] = buildings[\"buffer\"].apply(lambda x: shapely.geometry.mapping(x))\n",
    "\n",
    "# open aerial image raster mosaic\n",
    "in_tif = rasterio.open(in_filepath)\n",
    "\n",
    "for index, row in buildings.iterrows():\n",
    "   \n",
    "    # crop aerial image with building's buffer\n",
    "    out_img, out_meta = get_image_crop(crop_geometry_json = row[\"buffer_json\"],\n",
    "                                       in_tif = in_tif)\n",
    "    \n",
    "    # save crop as png\n",
    "    if save_img_as_png:\n",
    "        save_png_image(img_rio = out_img,\n",
    "                       dirpath = images_dirpath,\n",
    "                       filename = str(row[\"b_id\"]))\n",
    "    \n",
    "    # save crop as tif\n",
    "    if save_img_as_tif:\n",
    "        save_tif_image(img_rio = out_img,\n",
    "                       img_meta = out_meta,\n",
    "                       dirpath = images_dirpath,\n",
    "                       filename = str(row[\"b_id\"]))\n",
    "    \n",
    "    # get segments that intersect the building's buffer\n",
    "    label_segments = get_label_segments(segments = segments,\n",
    "                                        crop_geometry = row[\"buffer\"],\n",
    "                                        crop_crs = segments_crs)\n",
    "    \n",
    "    # rasterize these segments and save them as label pngs\n",
    "    save_png_labels(segments_geometry = label_segments[\"geometry\"],\n",
    "                    segments_orientation = label_segments[\"orientation_num\"],\n",
    "                    shape = (out_meta[\"width\"], out_meta[\"height\"]),\n",
    "                    transform = out_meta[\"transform\"],\n",
    "                    dirpath = labels_dirpath,\n",
    "                    filename = str(row[\"b_id\"]))\n",
    "    \n",
    "    print(f\"Sample {str(index+1)} done.\", end = \"\\r\")\n",
    "                                        \n",
    "in_tif.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed87212-c50e-4659-b51a-494390a85325",
   "metadata": {},
   "source": [
    "# Create random subsets of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f427f-70e7-4468-9388-879eaa451275",
   "metadata": {},
   "source": [
    "Not used for paper, may be used for testing or other purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589e9b0-3572-44c7-8526-eb6dad0b7a04",
   "metadata": {},
   "source": [
    "## Take random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36e04b-fdc8-4529-958a-1615da5219cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_subset = buildings.sample(n = 1878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f9f07-a303-4a0e-8f1f-4be9c59681c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = buildings.explore()\n",
    "buildings_subset.explore(m = m, color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b51cb-5b27-48b4-bfa5-c1e7ac23b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns \"centroid\" and \"buffer\" that inhibit functioning of to_file-function\n",
    "buildings_subset = buildings_subset.drop([\"centroid\", \"buffer\"], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220244da-5a19-4dae-a0cd-fc22ab47cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_subset.to_file(os.path.join(segments_dirpath, \"wbg_buildings_subset_20220117.geojson\"), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b32891-85bf-44f2-be82-22ef614ac3cc",
   "metadata": {},
   "source": [
    "## Relocate subset images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99135bb-46ac-480b-9d6a-2a74ed7ef5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirpath = r\"datasets\"\n",
    "dataset_dirname_src = \"dataset_wbg_v4\"\n",
    "dataset_dirname_dst = \"wbg_v4_subset\"\n",
    "images_dirpath_src = os.path.join(dataset_dirpath, dataset_dirname_src, \"images\")\n",
    "labels_dirpath_src = os.path.join(dataset_dirpath, dataset_dirname_src, \"labels\")\n",
    "images_dirpath_dst = os.path.join(dataset_dirpath, dataset_dirname_dst, \"images\")\n",
    "labels_dirpath_dst = os.path.join(dataset_dirpath, dataset_dirname_dst, \"labels\")\n",
    "images_filetype = \".tif\"\n",
    "labels_filetype = \".png\"\n",
    "if not os.path.exists(images_dirpath_dst): os.makedirs(images_dirpath_dst)\n",
    "if not os.path.exists(labels_dirpath_dst): os.makedirs(labels_dirpath_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce70965-1919-4da0-8a9a-b1bf8baf6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "relocate_samples(\n",
    "    ids = buildings_subset[\"b_id\"],\n",
    "    filetype = images_filetype,\n",
    "    dirpath_src = images_dirpath_src,\n",
    "    dirpath_dst = images_dirpath_dst\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93ce86-5299-49aa-a84a-dbd086c32db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "relocate_samples(\n",
    "    ids = buildings_subset[\"b_id\"],\n",
    "    filetype = labels_filetype,\n",
    "    dirpath_src = labels_dirpath_src,\n",
    "    dirpath_dst = labels_dirpath_dst\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc2f48-7ad1-4610-90e8-d35e80c526f6",
   "metadata": {},
   "source": [
    "## Update buildings dataframe to perform data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea2b97-2cff-4c7f-800d-4c96e925ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct buildings dataframe to perform data split\n",
    "buildings = buildings_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d3b20-89c2-4d1e-8b89-3513a9e549a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids\n",
    "buildings[\"centroid\"] = buildings.centroid\n",
    "\n",
    "# create square buffers around buildings to crop / retrieve aerial image\n",
    "buildings[\"buffer\"] = buildings[\"centroid\"].buffer(img_size_m/2, cap_style=3)\n",
    "\n",
    "# number of buildings that are not contained within the image-sized buffer\n",
    "sum(buildings[\"buffer\"].contains(buildings[\"geometry\"]) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f056302-f1c5-44cf-9254-df9b1660c890",
   "metadata": {},
   "source": [
    "# Perform data split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813e78a-64bf-449e-ad6a-a5c1dda77a64",
   "metadata": {},
   "source": [
    "## Prepare hand-labeled dataset: Filter out buildings without image/label pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffffc33-ffa4-401f-ba6b-335633f0de76",
   "metadata": {},
   "source": [
    "Only execute for manually labeled dataset (wbg_m aka _small-manu_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdbe9e-2b9e-4dcb-9ae9-f4ecf1d6928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from all buildings in pvbackend-database, select only those for which\n",
    "# an image-label-pair exists in the data provided by Sebastian.\n",
    "images_dirpath_src = r\"images_roof_centered_png\"\n",
    "images_filetype = \".png\"\n",
    "image_filenames = [file for file in os.listdir(images_dirpath_src) if file.lower().endswith(images_filetype)]\n",
    "\n",
    "image_ids = [int(fn[:-4]) for fn in image_filenames]\n",
    "b_ids = buildings[buildings[\"b_id\"].isin(image_ids)][\"b_id\"].tolist()\n",
    "\n",
    "buildings = buildings[buildings[\"b_id\"].isin(b_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133c84d-69fe-46de-a5cc-53979f63edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only to inform: number of segments that belong to these filtered buildings\n",
    "segments[segments[\"b_id\"].isin(buildings[\"b_id\"])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16bfd08-7659-45ad-9878-bc68ae565f16",
   "metadata": {},
   "source": [
    "## Split building dataframe into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbaec2-2a40-4593-8fe5-9a490a770da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the right table with locations and buildings numbers for validation\n",
    "# and test sets, depending on scenario that is being processed.\n",
    "\n",
    "val_test_points_dirpath = \"val_test_locations\"\n",
    "val_test_points_filenames = {\n",
    "    \"small-manu\":                         \"val_test_locations_small-manu_small-auto.csv\",\n",
    "    \"small-auto\":                         \"val_test_locations_small-manu_small-auto.csv\"\n",
    "    \"large-auto\":                         \"val_test_locations_large-auto.csv\",\n",
    "    \"small-auto_legacy\":                  \"val_test_locations_small-auto_legacy.csv\",  # If small-auto dataset uses small-auto building centroids instead of small-manu building centroids\n",
    "    \"large-auto_legacy\":                  \"val_test_locations_large-auto_legacy.csv\",\n",
    "    \"large-auto_legacy_Erding_Freising\":  \"val_test_locations_large-auto_legacy_Erding_Freising.csv\",\n",
    "    \"large-auto_legacy_Munich\":           \"val_test_locations_large-auto_legacy_Munich.csv\",\n",
    "    \"large-auto_legacy_Rural\":            \"val_test_locations_large-auto_legacy_Rural.csv\",\n",
    "}\n",
    "\n",
    "val_test_points_filepath = os.path.join(val_test_points_dirpath, val_test_points_filenames[scenario])\n",
    "val_test_points = gpd.read_file(val_test_points_filepath, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "val_test_points.crs = \"epsg:25832\"\n",
    "val_test_points[\"number\"] = val_test_points[\"number\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d9a49-735c-449e-a0e6-b620580f27d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set, test_areas, _ = get_data_subset(points = val_test_points.geometry[val_test_points[\"type\"] == \"test\"],\n",
    "                                          numbers = val_test_points.loc[val_test_points[\"type\"] == \"test\", \"number\"],\n",
    "                                          buildings = buildings)\n",
    "\n",
    "buildings_except_test_set_overlap = remove_overlapping_buildings(buildings, test_set)\n",
    "\n",
    "val_set, val_areas, _ = get_data_subset(points = val_test_points.geometry[val_test_points[\"type\"] == \"val\"],\n",
    "                                        numbers = val_test_points.loc[val_test_points[\"type\"] == \"val\", \"number\"],\n",
    "                                        buildings = buildings_except_test_set_overlap)\n",
    "\n",
    "train_set = remove_overlapping_buildings(buildings_except_test_set_overlap, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273eef01-cb55-44f0-9c64-3aaf3a8c6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the found subsets as geojson files\n",
    "train_set_geojson = train_set.drop([\"centroid\", \"buffer\"], axis = \"columns\")\n",
    "val_set_geojson = val_set.drop([\"centroid\", \"buffer\"], axis = \"columns\")\n",
    "test_set_geojson = test_set.drop([\"centroid\", \"buffer\"], axis = \"columns\")\n",
    "\n",
    "train_set_geojson.to_file(\"\".join([scenario, \"_train_set.geojson\"]), driver = \"GeoJSON\")\n",
    "val_set_geojson.to_file(\"\".join([scenario, \"_val_set.geojson\"]), driver = \"GeoJSON\")\n",
    "test_set_geojson.to_file(\"\".join([scenario, \"_test_set.geojson\"]), driver = \"GeoJSON\")\n",
    "\n",
    "val_areas.to_file(\"\".join([scenario, \"_val_areas.geojson\"]), driver = \"GeoJSON\")\n",
    "test_areas.to_file(\"\".join([scenario, \"_test_areas.geojson\"]), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72609893-05ac-413c-815c-5cdb1bd50830",
   "metadata": {},
   "source": [
    "## Relocate images and labels accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8627d-317e-4903-ab39-1c721f25b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirpath = r\"datasets\"\n",
    "dataset_dirname = \"dataset_bv_complete\"\n",
    "images_dirpath = os.path.join(dataset_dirpath, dataset_dirname, \"images\")\n",
    "labels_dirpath = os.path.join(dataset_dirpath, dataset_dirname, \"labels\")\n",
    "images_filetype = \".tif\"\n",
    "labels_filetype = \".png\"\n",
    "\n",
    "if not os.path.exists(images_dirpath): raise RuntimeError(\"Could not find images directory.\")\n",
    "if not os.path.exists(labels_dirpath): raise RuntimeError(\"Could not find labels directory.\")\n",
    "\n",
    "ids = [train_set[\"b_id\"], train_set[\"b_id\"], val_set[\"b_id\"], val_set[\"b_id\"], test_set[\"b_id\"], test_set[\"b_id\"]]\n",
    "filetypes = 3 * [images_filetype, labels_filetype]\n",
    "dirpaths_src = 3 * [images_dirpath, labels_dirpath]\n",
    "dirnames_dst = [\"train\", \"trainannot\", \"val\", \"valannot\", \"test\", \"testannot\"]\n",
    "dirpaths_dst = [os.path.join(dataset_dirpath, dataset_dirname, dirname) for dirname in dirnames_dst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd60a8-c6b6-4cb8-9fff-242d66d03017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dirpath in enumerate(dirpaths_dst):\n",
    "    if not os.path.exists(dirpath): os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e4868-3ca4-47c9-9d41-660df3de9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    relocate_samples(ids[i], filetypes[i], dirpaths_src[i], dirpaths_dst[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c9436-14b2-426b-bdb5-ebdd67a4ee33",
   "metadata": {},
   "source": [
    "# Determine class ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7486d09-d488-4f48-ad87-d78067da1129",
   "metadata": {},
   "source": [
    "Which proportion of all pixels in a dataset is taken up by each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0288906-90d0-41bb-9682-bb5d5cb0ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirpath = r\"datasets\"\n",
    "dataset_dirname = \"dataset_wbg_v4\"\n",
    "labels_dirpath = os.path.join(dataset_dirpath, dataset_dirname, \"labels\")\n",
    "\n",
    "labels_filetype = \".png\"\n",
    "label_filenames = [file for file in os.listdir(labels_dirpath) if file.lower().endswith(labels_filetype)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a4abd-0351-44d1-9071-926e305a196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "\n",
    "count = np.zeros(18)\n",
    "for i, filename in enumerate(label_filenames):\n",
    "    filepath = os.path.join(labels_dirpath, filename)\n",
    "    labelimg = cv2.imread(filepath)\n",
    "    \n",
    "    print(\"Read {} files.\".format(str(i+1)), end = \"\\r\")\n",
    "    \n",
    "    count += np.bincount(labelimg[:,:,0].reshape(-1), minlength = 18)\n",
    "\n",
    "ratios = np.multiply(count, 1/sum(count))\n",
    "\n",
    "e = time.time()\n",
    "print(\"Read {} files in {} seconds.\".format(str(i+1), str(e-b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c34b4-ed88-416b-aa97-92f2e28bcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_dict = dict(zip(range(0,18), ratios))\n",
    "ratios_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
